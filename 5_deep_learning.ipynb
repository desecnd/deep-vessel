{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xWDCu8h5KGH",
        "outputId": "a64e8187-a69e-4c2b-d5ab-12f8f62b5214"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Mt3KoFR4drG",
        "outputId": "2a35bb16-9f3e-438b-e19b-b9478d69c037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras_unet in /usr/local/lib/python3.9/dist-packages (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RHnpPf-4LIn",
        "outputId": "4c23dd3e-123c-4801-8017-2a11c19e5d93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------\n",
            "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import keras_unet.utils as kutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (14, 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X-_Wbijj6CfD"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "DATA_DIR = \"data\"\n",
        "GOLD_STANDARD_DIR = \"manual1\" \n",
        "FOV_DIR = \"mask\" \n",
        "IMAGE_DIR = \"images\"\n",
        "\n",
        "def load_image(sample_name: str):\n",
        "    sample_dir = Path(DATA_DIR) / Path(IMAGE_DIR)\n",
        "\n",
        "    for ext in [ '.jpg', '.JPG' ]:\n",
        "        sample = sample_dir / Path(sample_name + ext)\n",
        "        if sample.is_file:\n",
        "            return plt.imread(str(sample))\n",
        "\n",
        "    raise FileNotFoundError\n",
        "\n",
        "def load_fov(sample_name: str):\n",
        "    sample_dir = Path(DATA_DIR) / Path(FOV_DIR)\n",
        "\n",
        "    sample = sample_dir / Path(sample_name + '_mask.tif')\n",
        "    if not sample.is_file:\n",
        "        raise FileNotFoundError\n",
        "\n",
        "    return cv2.imread(str(sample), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "def load_gold_standard(sample_name: str):\n",
        "    sample_dir = Path(DATA_DIR) / Path(GOLD_STANDARD_DIR)\n",
        "\n",
        "    sample = sample_dir / Path(sample_name + '.tif')\n",
        "    if not sample.is_file:\n",
        "        raise FileNotFoundError\n",
        "\n",
        "    # load image in grayscale\n",
        "    return cv2.imread(str(sample), cv2.IMREAD_GRAYSCALE)\n",
        "  \n",
        "def get_all_sample_names() -> List[str]:\n",
        "    \"\"\" Return list of strings - names of given samples. We can get from names to images, fovs, and gold_standards \"\"\"\n",
        "    \n",
        "    # Use files from Gold Standards, because they have basic names + tif extension\n",
        "    samples_dir = Path(DATA_DIR) / Path(GOLD_STANDARD_DIR)\n",
        "\n",
        "    # data/manual1/01_dr.tif -> 01_dr\n",
        "    sample_names = [ sample_file.stem for sample_file in samples_dir.iterdir() ] \n",
        "    return sample_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-UAXxzrV4LIn"
      },
      "outputs": [],
      "source": [
        "PATCH_SIZE = 256\n",
        "PATCH_STRIDE = 128\n",
        "\n",
        "def get_batch_names(sample_names, num_batches):\n",
        "    return np.array_split(sample_names, num_batches)\n",
        "\n",
        "def get_batch_data(sample_names, val_sample_names, patch_size=PATCH_SIZE, patch_stride=PATCH_STRIDE):\n",
        "    x_train = kutils.get_patches(\n",
        "        np.array([load_image(path) for path in sample_names], dtype=np.float32),\n",
        "        size=patch_size,\n",
        "        stride=patch_stride\n",
        "    )\n",
        "    y_train = kutils.get_patches(\n",
        "        np.expand_dims(np.array([load_gold_standard(path) for path in sample_names], dtype=np.float32), -1),\n",
        "        size=patch_size,\n",
        "        stride=patch_stride\n",
        "    )\n",
        "    x_val = kutils.get_patches(\n",
        "        np.array([load_image(path) for path in val_sample_names], dtype=np.float32),\n",
        "        size=patch_size,\n",
        "        stride=patch_stride\n",
        "    )\n",
        "    y_val = kutils.get_patches(\n",
        "        np.expand_dims(np.array([load_gold_standard(path) for path in val_sample_names], dtype=np.float32), -1),\n",
        "        size=patch_size,\n",
        "        stride=patch_stride\n",
        "    )\n",
        "\n",
        "    x_train /= 255\n",
        "    y_train /= 255\n",
        "    x_val /= 255\n",
        "    y_val /= 255\n",
        "    \n",
        "    return x_train, y_train, x_val, y_val\n",
        "\n",
        "x_train = kutils.get_patches(\n",
        "    np.array([load_image(path) for path in ['01_dr']]),\n",
        "    size=PATCH_SIZE,\n",
        "    stride=PATCH_STRIDE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5-hWPj3v4LIn"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "# x_len = x_train.shape[0] + x_val.shape[0]\n",
        "\n",
        "# train_data = kutils.get_augmented(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rlPigc8l4LI4"
      },
      "outputs": [],
      "source": [
        "from keras_unet.models import custom_unet\n",
        "from keras_unet.metrics import iou, iou_thresholded\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras.optimizers import SGD\n",
        "import os\n",
        "\n",
        "model = custom_unet(input_shape=x_train[0].shape)\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    'fundus_segm_v1.h5',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "if os.path.exists(\"model_history_log.csv\"):\n",
        "    os.remove(\"model_history_log.csv\")\n",
        "\n",
        "csv_logger = CSVLogger(\"model_history_log.csv\", append=True)\n",
        "\n",
        "model.compile(\n",
        "    SGD(learning_rate=0.01),\n",
        "    \"binary_crossentropy\",\n",
        "    metrics=[iou]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJkVoUBX4LI4",
        "outputId": "8c63f974-6317-4c86-ec4e-13b587325da2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 16  432         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 256, 256, 16  64         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " spatial_dropout2d (SpatialDrop  (None, 256, 256, 16  0          ['batch_normalization[0][0]']    \n",
            " out2D)                         )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 16  2304        ['spatial_dropout2d[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 256, 256, 16  64         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 16  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 32  4608        ['max_pooling2d[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128, 128, 32  128        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " spatial_dropout2d_1 (SpatialDr  (None, 128, 128, 32  0          ['batch_normalization_2[0][0]']  \n",
            " opout2D)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 32  9216        ['spatial_dropout2d_1[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 128, 128, 32  128        ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)  0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 64, 64, 64)   18432       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " spatial_dropout2d_2 (SpatialDr  (None, 64, 64, 64)  0           ['batch_normalization_4[0][0]']  \n",
            " opout2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 64)   36864       ['spatial_dropout2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 128)  73728       ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " spatial_dropout2d_3 (SpatialDr  (None, 32, 32, 128)  0          ['batch_normalization_6[0][0]']  \n",
            " opout2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 128)  147456      ['spatial_dropout2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 128)  0          ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 256)  294912      ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " spatial_dropout2d_4 (SpatialDr  (None, 16, 16, 256)  0          ['batch_normalization_8[0][0]']  \n",
            " opout2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 256)  589824      ['spatial_dropout2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 32, 32, 128)  131200     ['batch_normalization_9[0][0]']  \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 32, 32, 256)  0           ['conv2d_transpose[0][0]',       \n",
            "                                                                  'batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 128)  294912      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 32, 32, 128)  512        ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 32, 128)  147456      ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 32, 32, 128)  512        ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 64)  32832       ['batch_normalization_11[0][0]'] \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 64, 64, 128)  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 64, 64, 64)   73728       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 64, 64, 64)  256         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 64, 64, 64)   36864       ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 64, 64, 64)  256         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 32  8224       ['batch_normalization_13[0][0]'] \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128, 128, 64  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                )                                 'batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 128, 128, 32  18432       ['concatenate_2[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 128, 128, 32  128        ['conv2d_14[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 128, 128, 32  9216        ['batch_normalization_14[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 128, 128, 32  128        ['conv2d_15[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 16  2064       ['batch_normalization_15[0][0]'] \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 256, 256, 32  0           ['conv2d_transpose_3[0][0]',     \n",
            "                                )                                 'batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 256, 256, 16  4608        ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 256, 256, 16  64         ['conv2d_16[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 256, 256, 16  2304        ['batch_normalization_16[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 256, 256, 16  64         ['conv2d_17[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 256, 256, 1)  17          ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,945,521\n",
            "Trainable params: 1,942,577\n",
            "Non-trainable params: 2,944\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "LOZeuuUI4LI4",
        "outputId": "26157b3c-925e-40ac-b287-746ef1021963"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "real epoch 0 starts here.\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0974 - iou: 0.4767 - val_loss: 0.0907 - val_iou: 0.4340\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0980 - iou: 0.4562 - val_loss: 0.0797 - val_iou: 0.4858\n",
            "14/14 [==============================] - 19s 1s/step - loss: 0.0907 - iou: 0.4524 - val_loss: 0.0767 - val_iou: 0.5106\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.1137 - iou: 0.5075 - val_loss: 0.0826 - val_iou: 0.5415\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0923 - iou: 0.4563 - val_loss: 0.0863 - val_iou: 0.4436\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0999 - iou: 0.4739 - val_loss: 0.0736 - val_iou: 0.5176\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0939 - iou: 0.5161 - val_loss: 0.0746 - val_iou: 0.5396\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.1099 - iou: 0.5391 - val_loss: 0.0762 - val_iou: 0.5162\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0913 - iou: 0.5518 - val_loss: 0.0737 - val_iou: 0.5432\n",
            "real epoch 1 starts here.\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0950 - iou: 0.4860 - val_loss: 0.0931 - val_iou: 0.4259\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.1021 - iou: 0.4492 - val_loss: 0.0796 - val_iou: 0.4715\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0884 - iou: 0.4534 - val_loss: 0.0759 - val_iou: 0.5033\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.1192 - iou: 0.4959 - val_loss: 0.0797 - val_iou: 0.5390\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-926d7e088068>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sample_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# train_data = kutils.get_augmented(x_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-323710e38a26>\u001b[0m in \u001b[0;36mget_batch_data\u001b[0;34m(sample_names, val_sample_names, patch_size, patch_stride)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_batch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sample_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATCH_STRIDE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     x_train = kutils.get_patches(\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_stride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-323710e38a26>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_batch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sample_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATCH_STRIDE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     x_train = kutils.get_patches(\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_stride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-69881a6b43da>\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(sample_name)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2193\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1564\u001b[0m         return (_pil_png_to_float_array(image)\n\u001b[1;32m   1565\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImagePlugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImageFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m                 pil_to_array(image))\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mpil_to_array\u001b[0;34m(pilImage)\u001b[0m\n\u001b[1;32m   1708\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpilImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'RGBA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RGBX'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RGB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m         \u001b[0;31m# return MxNx4 RGBA, MxNx3 RBA, or MxN luminance array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpilImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpilImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'I;16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;31m# return MxN luminance array of uint16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m             \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mclass\u001b[0m \u001b[0mArrayData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;31m# unpack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m                         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodermaxblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m                             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                                 \u001b[0;31m# truncated png/gif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/JpegImagePlugin.py\u001b[0m in \u001b[0;36mload_read\u001b[0;34m(self, read_bytes)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mso\u001b[0m \u001b[0mlibjpeg\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mfinish\u001b[0m \u001b[0mdecoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \"\"\"\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOAD_TRUNCATED_IMAGES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import gc\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "sample_names = list(filter(lambda x: '0' in x and '9' not in x, get_all_sample_names()))\n",
        "val_sample_names = list(filter(lambda x: '09' in x, get_all_sample_names()))\n",
        "\n",
        "for i in range(4):\n",
        "    print('real epoch', i, 'starts here.')\n",
        "    for batch_names in get_batch_names(sample_names, 9):\n",
        "        gc.collect()\n",
        "        \n",
        "        x_train, y_train, x_val, y_val = get_batch_data(batch_names, val_sample_names)\n",
        "\n",
        "        # train_data = kutils.get_augmented(x_train, y_train)\n",
        "\n",
        "        # model.fit_generator(\n",
        "        #     train_data,\n",
        "        #     steps_per_epoch=2,\n",
        "        #     epochs = 1,\n",
        "        #     validation_data=(x_val, y_val),\n",
        "        #     callbacks=[checkpoint_callback, csv_logger]\n",
        "        # )\n",
        "\n",
        "        model.fit(\n",
        "            x_train,\n",
        "            y_train,\n",
        "            batch_size = 64,\n",
        "            epochs = 1,\n",
        "            validation_data=(x_val, y_val),\n",
        "            callbacks=[checkpoint_callback, csv_logger]\n",
        "        )\n",
        "\n",
        "        del x_train\n",
        "        del y_train\n",
        "        del x_val\n",
        "        del y_val\n",
        "\n",
        "model.save('fundus_segm_v1_final.h5')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GU0ZfROH4LI4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 2336, 3504, 3)\n",
            "10/10 [==============================] - 23s 2s/step\n",
            "(289, 256, 256, 3) (289, 256, 256, 1)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "need at least one array to stack",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Jakub\\Desktop\\iwm\\deep-vessel\\5_deep_learning.ipynb Cell 11\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jakub/Desktop/iwm/deep-vessel/5_deep_learning.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(x_test\u001b[39m.\u001b[39mshape, y_pred\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jakub/Desktop/iwm/deep-vessel/5_deep_learning.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# kutils.plot_patches(\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jakub/Desktop/iwm/deep-vessel/5_deep_learning.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m#     img_arr=y_pred, # required - array of cropped out images\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jakub/Desktop/iwm/deep-vessel/5_deep_learning.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m#     org_img_size=(y_pred.shape[1] * y_pred.shape[0], y_pred.shape[2] * y_pred.shape[0]), # required - original size of the image\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jakub/Desktop/iwm/deep-vessel/5_deep_learning.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m#     stride=PATCH_STRIDE)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Jakub/Desktop/iwm/deep-vessel/5_deep_learning.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m pp \u001b[39m=\u001b[39m kutils\u001b[39m.\u001b[39;49mreconstruct_from_patches(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jakub/Desktop/iwm/deep-vessel/5_deep_learning.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     np\u001b[39m.\u001b[39;49marray([y_pred]),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jakub/Desktop/iwm/deep-vessel/5_deep_learning.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     org_img_size\u001b[39m=\u001b[39;49m(y_pred\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m] \u001b[39m*\u001b[39;49m y_pred\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], y_pred\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m] \u001b[39m*\u001b[39;49m y_pred\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jakub/Desktop/iwm/deep-vessel/5_deep_learning.ipynb#X12sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     stride\u001b[39m=\u001b[39;49mPATCH_STRIDE\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jakub/Desktop/iwm/deep-vessel/5_deep_learning.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jakub/Desktop/iwm/deep-vessel/5_deep_learning.ipynb#X12sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m kutils\u001b[39m.\u001b[39mplot_imgs(xx, yy, pp)\n",
            "File \u001b[1;32mc:\\Users\\Jakub\\miniconda3\\envs\\intro\\lib\\site-packages\\keras_unet\\utils.py:469\u001b[0m, in \u001b[0;36mreconstruct_from_patches\u001b[1;34m(img_arr, org_img_size, stride, size)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[39m# TODO add averaging for masks - right now it's just overwritting\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \n\u001b[0;32m    458\u001b[0m     \u001b[39m#         for layer in range(nm_layers):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[39m#             img_bg[i_max*stride:i_max*stride+stride, i_max*stride:i_max*stride+stride, layer] *= averaging_value\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     \u001b[39m#             img_bg[0:stride, i_max*stride:i_max*stride+stride, layer] *= averaging_value\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     images_list\u001b[39m.\u001b[39mappend(img_bg)\n\u001b[1;32m--> 469\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mstack(images_list)\n",
            "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\Jakub\\miniconda3\\envs\\intro\\lib\\site-packages\\numpy\\core\\shape_base.py:422\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out)\u001b[0m\n\u001b[0;32m    420\u001b[0m arrays \u001b[39m=\u001b[39m [asanyarray(arr) \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m    421\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m arrays:\n\u001b[1;32m--> 422\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mneed at least one array to stack\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    424\u001b[0m shapes \u001b[39m=\u001b[39m {arr\u001b[39m.\u001b[39mshape \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m arrays}\n\u001b[0;32m    425\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(shapes) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n",
            "\u001b[1;31mValueError\u001b[0m: need at least one array to stack"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras_unet.metrics import iou\n",
        "\n",
        "test_sample_names = ['15_dr'] #list(filter(lambda x: '0' not in x, get_all_sample_names()))\n",
        "\n",
        "model = keras.models.load_model('fundus_segm_v1.h5', custom_objects={'iou': iou})\n",
        "\n",
        "xx = np.array([load_image(path) for path in test_sample_names], dtype=np.float32)\n",
        "x_test = kutils.get_patches(\n",
        "    xx,\n",
        "    size=PATCH_SIZE,\n",
        "    stride=PATCH_STRIDE\n",
        ")\n",
        "\n",
        "yy = np.expand_dims(np.array([load_gold_standard(path) for path in test_sample_names], dtype=np.float32), -1)\n",
        "y_test = kutils.get_patches(\n",
        "    yy,\n",
        "    size=PATCH_SIZE,\n",
        "    stride=PATCH_STRIDE\n",
        ")\n",
        "\n",
        "print(xx.shape)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "print(x_test.shape, y_pred.shape)\n",
        "\n",
        "# kutils.plot_patches(\n",
        "#     img_arr=y_pred, # required - array of cropped out images\n",
        "#     org_img_size=(y_pred.shape[1] * y_pred.shape[0], y_pred.shape[2] * y_pred.shape[0]), # required - original size of the image\n",
        "#     stride=PATCH_STRIDE)\n",
        "\n",
        "pp = kutils.reconstruct_from_patches(\n",
        "    np.array([y_pred]),\n",
        "    org_img_size=(y_pred.shape[1] * y_pred.shape[0], y_pred.shape[2] * y_pred.shape[0]),\n",
        "    stride=PATCH_STRIDE\n",
        ")\n",
        "\n",
        "kutils.plot_imgs(xx, yy, pp)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "intro",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
